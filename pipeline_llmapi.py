from openai import OpenAI
import os, json
from dotenv import load_dotenv
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity 
import pandas as pd
from tqdm.auto import tqdm
import re
import ast


class LLMClassifier:
    def __init__(self, env_path='.env', summary_infos_path='summary_infos2.json', 
                 summary_dict_kor_path='summary_dict_kor.json', TYPE_TO_SECTIONS_path='TYPE_TO_SECTIONS.json'):
        """
        LLMì„ ì´ìš©í•œ í…ìŠ¤íŠ¸ ë¶„ë¥˜ ë° ìƒì„± í´ë˜ìŠ¤
        
        Args:
            env_path (str): .env íŒŒì¼ ê²½ë¡œ
            summary_infos_path (str): summary_infos2.json íŒŒì¼ ê²½ë¡œ
            summary_dict_kor_path (str): summary_dict_kor.json íŒŒì¼ ê²½ë¡œ
            TYPE_TO_SECTIONS_path (str): TYPE_TO_SECTIONS.json íŒŒì¼ ê²½ë¡œ
        """
        # í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
        dotenv_path = os.path.join(os.getcwd(), '.', env_path)
        load_dotenv(dotenv_path)
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.client = OpenAI(api_key=os.getenv("GPT_API_KEY"))
        
        self.path = './jsons/'
        # JSON íŒŒì¼ë“¤ ë¡œë“œ
        with open(self.path + summary_infos_path, 'r', encoding='utf-8') as f:
            self.summary_infos = json.load(f)
        with open(self.path + summary_dict_kor_path, 'r', encoding='utf-8') as f:
            self.summary_dict_kor = json.load(f)
        with open(self.path + TYPE_TO_SECTIONS_path, 'r', encoding='utf-8') as f:
            self.TYPE_TO_SECTIONS = json.load(f)
        
        # ì¹´í˜ ëª©ë¡
        self.cafes = ['fashion', 'health', 'etc', 'mom']
        
        # ê¸°ë³¸ ì½˜í…ì¸  íƒ€ì…
        self.DEFAULT_TYPE = 'ë”œ/í”„ë¡œëª¨ì…˜(í•«ë”œÂ·í• ì¸Â·ì¿ í°Â·ì¦ì •)'
    

    def get_emoticon_guide(self, cafe_tone_json):
        """ì´ëª¨í‹°ì½˜ ì‚¬ìš© ê°€ì´ë“œ ìƒì„±"""
        emoticon_ratio = float(cafe_tone_json.get('ì´ëª¨í‹°ì½˜ ë¹„ìœ¨', '0%').replace('%', ''))
        if emoticon_ratio >= 20:
            return "ì´ëª¨í‹°ì½˜ì„ ìì£¼ ì‚¬ìš©í•˜ì„¸ìš” (ğŸ˜Š, ğŸ‘, ğŸ’•, ğŸ”¥ ë“±ì„ ë¬¸ì¥ ì‚¬ì´ì‚¬ì´ ì ì ˆíˆ ë°°ì¹˜)"
        elif emoticon_ratio >= 15:
            return "ì´ëª¨í‹°ì½˜ì„ ì¢…ì¢… ì‚¬ìš©í•˜ì„¸ìš” (ğŸ˜Š, ğŸ‘ ì •ë„ë¥¼ 2-3ë²ˆ í¬í•¨)"
        elif emoticon_ratio >= 10:
            return "ì´ëª¨í‹°ì½˜ì„ ê°€ë” ì‚¬ìš©í•˜ì„¸ìš” (ğŸ˜Š ë˜ëŠ” ğŸ‘ ì„ 1-2ë²ˆ í¬í•¨)"
        elif emoticon_ratio >= 5:
            return "ì´ëª¨í‹°ì½˜ì„ ì ê²Œ ì‚¬ìš©í•˜ì„¸ìš” (ğŸ˜Š ì •ë„ë¥¼ 1ë²ˆë§Œ í¬í•¨)"
        else:
            return "ì´ëª¨í‹°ì½˜ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”"
        
    """ë¸Œëœë“œ ì¶”ì¶œìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    def prompt1(self, title, summary_f_toks):
        message = f"""
        ì•„ë˜ ê¸€ì˜ "ëŒ€í‘œë¸Œëœë“œ(b)"ì™€ "ì œëª© ë‚´í¬ ì—¬ë¶€(f)"ë¥¼ ì¶”ì¶œí•´ JSONë§Œ ë°˜í™˜í•˜ë¼.
        ë°˜í™˜ í˜•ì‹: {{"b": <str>, "f": <int>}}
        ê·œì¹™:
        - ìš°ì„ ìˆœìœ„: ì œëª© > ìš”ì•½í† í°.
        - ì—¬ëŸ¬ í›„ë³´ë©´ ê°€ì¥ ëª…ì‹œì  íŒë§¤/í–‰ì‚¬ ì£¼ì²´ ë˜ëŠ” ìµœë‹¤ ë¹ˆë„ 1ê°œ.
        - ëª¨ë¸ëª…/ì œí’ˆêµ°/í–‰ì‚¬ëª… ì œì™¸, ë¸Œëœë“œ(íšŒì‚¬/ìŠ¤í† ì–´ëª…)ë§Œ.
        - "ë¡œì¼“ë°°ì†¡/ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´/ë¼ì´ë¸Œì»¤ë¨¸ìŠ¤/ì¿ í°" ë“± í”Œë«í¼/ê¸°ëŠ¥ ì œì™¸.
        - ì˜¨ë¼ì¸ ì¤„ì„ë§/ì˜ë¬¸ ì•½ì¹­ì„ í•œê¸€ í’€ë„¤ì„ìœ¼ë¡œ í‘œê¸°(ì˜ˆ: LGâ†’ì—˜ì§€, KBì¦ê¶Œâ†’ì¼€ì´ë¹„ì¦ê¶Œ).
        - ë¸Œëœë“œë¥¼ ëª» ì°¾ëŠ” ê²½ìš°:
        - ì´ë²¤íŠ¸ì„± ê²Œì‹œë¬¼ì´ë©´ í–‰ì‚¬ ì£¼ìµœì‚¬ë¥¼ bë¡œ ë°˜í™˜.
        - ê·¸ë˜ë„ ë¶ˆê°€í•˜ë©´ "ë¯¸ì •".
        - f: ëŒ€í‘œë¸Œëœë“œ íŒë‹¨ì„ ì œëª©ìœ¼ë¡œ í–ˆë‹¤ë©´ 1, ì•„ë‹ˆë©´ 0.
        - ëª¨ë“  ë°˜í™˜ì€ í•œê¸€. ë°°ì—´([]) ê¸ˆì§€, ì½”ë“œíœìŠ¤/ì—¬ë¶„ í…ìŠ¤íŠ¸ ê¸ˆì§€, ì„¤ëª… ê¸ˆì§€. JSON 1ê°œë§Œ.

        ì œëª©: {title}
        ìš”ì•½í† í°: {summary_f_toks}
        """
        return message.strip()


    """ì½˜í…ì¸  ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    def prompt2(self, product, cafe_tone_json, content_type_str):
        picked_type = self.DEFAULT_TYPE if content_type_str=='ë°ì´í„°X' else content_type_str
        sections = self.TYPE_TO_SECTIONS.get(picked_type, self.TYPE_TO_SECTIONS[self.DEFAULT_TYPE])
        emoticon_guide = self.get_emoticon_guide(cafe_tone_json)
        message = f"""
        ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•˜ê³ , í‚¤ëŠ” ì •í™•íˆ "title"ê³¼ "content" ë‘ ê°œë§Œ ì‚¬ìš©í•˜ë¼.
        ë§ˆí¬ë‹¤ìš´/ì½”ë“œë¸”ë¡/ë¶ˆë¦¿/ë²ˆí˜¸/ì„¹ì…˜ëª…(ì˜ˆ: í›…, ì¥ì , ë°©ë²•, ì£¼ì˜, CTA ë“±) ë° ì–´ë–¤ ë¼ë²¨ë„ ì¶œë ¥í•˜ì§€ ë§ˆë¼.
        ì¼ë°˜ ë¬¸ì¥ë“¤ë¡œë§Œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ì„±í•˜ë¼.

        [ì…ë ¥]
        - ìƒí’ˆëª…: {product}
        - ì¹´í˜ í†¤ ì§€í‘œ(JSON): {json.dumps(cafe_tone_json, ensure_ascii=False)}
        - ì„ íƒëœ ë³¸ë¬¸ ìœ í˜•: {picked_type}

        [í†¤ ê·œì¹™]
        - í•´ìš”/í•©ë‹ˆë‹¤: "í•´ìš”ì²´ ë¹„ìœ¨" > "í•©ë‹ˆë‹¤ì²´ ë¹„ìœ¨"ì´ë©´ í•´ìš”ì²´, ì•„ë‹ˆë©´ í•©ë‹ˆë‹¤ì²´.
        - ì¡°ê±´Â·í• ì¸ìœ¨ ê°™ì€ ìˆ«ìëŠ” ë‚˜ì—´í•˜ì§€ ë§ê³ , ë¬¸ì¥ ì†ì— ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ì„œ ì„¤ëª…í•œë‹¤.
        - ë‹¨ìˆœ ì •ë³´ ë‚˜ì—´ ëŒ€ì‹ , ì‹¤ì œ ì‚¬ìš© ê²½í—˜ë‹´ì´ë‚˜ ê°ì • í‘œí˜„(í¸í•˜ë‹¤, ì¢‹ì•˜ë‹¤, ì•„ì‰½ë‹¤ ë“±)ì„ ì„ì–´ì¤€ë‹¤.

        [ì´ëª¨í‹°ì½˜ ë° í‘œí˜„ ê·œì¹™]
        - {emoticon_guide} 
        - ì´ëª¨í‹°ì½˜ ë’¤ì—ëŠ” ë¬¸ì¥ë³´í˜¸ '.' ì„ ë„£ì§€ ì•ŠëŠ”ë‹¤.

        [ë‚´ìš© êµ¬ì„± ê°€ì´ë“œ]
        - {sections}

        [ì œëª© ê·œì¹™]
        - 25ì ë‚´ì™¸, ì¤‘ë³µêµ¬ë‘ì  ê¸ˆì§€, ìƒí’ˆ í‚¤ì›Œë“œ 1ê°œ í¬í•¨ ê¶Œì¥.

        [ì¶œë ¥ í˜•ì‹]
        {{"title":"<ë¬¸ìì—´>","content":"<ë¬¸ìì—´>"}}
        """
        return message.strip()
            
        
    def classify(self, prompt_text):
        """í†µí•© ë¶„ë¥˜ ì‹¤í–‰ - ë¸Œëœë“œ ì¶”ì¶œê³¼ ì½˜í…ì¸  ìƒì„± ëª¨ë‘ ì²˜ë¦¬"""
        r = self.client.responses.create(
            model="gpt-5-nano",
            input=prompt_text,
            reasoning={"effort":"low"},
            text={"verbosity": "low"}
        )
        txt = r.output_text
        if not txt:
            try:
                txt = r.output[0].content[0].text
            except Exception:
                for part in getattr(r.output[0], "content", []):
                    if getattr(part, "type", "") == "text":
                        txt = part.text
                        break
        return json.loads(txt)
    

    def process_brand_extraction(self, title, summary_f_toks):
        """
        ë¸Œëœë“œ ì¶”ì¶œ í”„ë¡œì„¸ìŠ¤
        
        Args:
            title (str): ì œëª©
            summary_f_toks (str): ìš”ì•½ í† í°ë“¤
            
        Returns:
            dict: ë¸Œëœë“œ ì¶”ì¶œ ê²°ê³¼
        """
        prompt_text = self.prompt1(title, summary_f_toks)
        result = self.classify(prompt_text)
        
        return {
            # 'title': title,
            # 'summary_f_toks': summary_f_toks,
            # 'brand_result': result,
            'brand': result.get('b', 'ë¯¸ì •'),
            # 'title_based': result.get('f', 0)
        }
    
    def process_content_generation(self, product, ptype):
        """
        ì½˜í…ì¸  ìƒì„± í”„ë¡œì„¸ìŠ¤ (ëª¨ë“  ì¹´í˜ íƒ€ì…ì— ëŒ€í•´)
        
        Args:
            product (str): ìƒí’ˆëª…
            ptype (str): ìƒí’ˆ ìœ í˜•
            
        Returns:
            dict: ëª¨ë“  ì¹´í˜ íƒ€ì…ë³„ ìƒì„± ê²°ê³¼
        """
        results = {
            'product': product,
            'ptype': ptype,
            'cafe_results': {}
        }
        
        for ctype in self.cafes:
            try:
                prompt_text = self.prompt2(
                    product, 
                    self.summary_dict_kor[ctype], 
                    self.summary_infos[ctype][ptype]
                )
                answer = self.classify(prompt_text)
                
                results['cafe_results'][ctype] = {
                    'success': True,
                    # 'result': answer,
                    'title': answer.get('title', ''),
                    'summary': answer.get('content', ''),
                }
            except Exception as e:
                results['cafe_results'][ctype] = {
                    'success': False,
                    'error': str(e),

                }
        
        return results

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    classifier = LLMClassifier()
    
    # ë¸Œëœë“œ ì¶”ì¶œë§Œ ì‹¤í–‰
    title = 'ì´ê±´ ì œëª©ì…ë‹ˆë‹¤'
    summary_f_toks = 'ë³¸ë¬¸'
    brand_result = classifier.process_brand_extraction(title, summary_f_toks)
    print("Brand extraction result:", brand_result)
    
    # ì½˜í…ì¸  ìƒì„±ë§Œ ì‹¤í–‰
    product = 'í…ŒìŠ¤íŠ¸ ìƒí’ˆ'
    ptype = 'íŒ¨ì…˜'
    content_result = classifier.process_content_generation(product, ptype)
    print("Content generation result:", content_result)
    